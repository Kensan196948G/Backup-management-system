"""
PostgreSQLç›£è¦–Celeryã‚¿ã‚¹ã‚¯
Phase 13: ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ

å®šæœŸçš„ã«PostgreSQLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç›£è¦–ã—ã€
å•é¡ŒãŒã‚ã‚Œã°ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç™ºè¡Œã—ã¾ã™ã€‚
"""

import logging
from datetime import datetime
from typing import Any, Dict

from app.tasks import celery_app

logger = logging.getLogger(__name__)


@celery_app.task(
    bind=True,
    name="app.tasks.postgres_monitoring.check_performance",
    max_retries=1,
)
def check_postgres_performance(self) -> Dict[str, Any]:
    """
    PostgreSQLãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯

    ç›£è¦–é …ç›®:
    - æ¥ç¶šæ•°ï¼ˆè­¦å‘Š: >80, å±é™º: >95ï¼‰
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ï¼ˆè­¦å‘Š: <90%, å±é™º: <80%ï¼‰
    - ãƒ‡ãƒƒãƒ‰ã‚¿ãƒ—ãƒ«ç‡ï¼ˆè­¦å‘Š: >10%, å±é™º: >20%ï¼‰

    Returns:
        ãƒã‚§ãƒƒã‚¯çµæœ
    """
    from app.services.postgres_monitor_service import PostgresMonitorService
    from app.tasks.notification_tasks import send_multi_channel_notification

    task_id = self.request.id
    logger.info(f"[Task {task_id}] PostgreSQLãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯é–‹å§‹")

    result = {
        "task_id": task_id,
        "timestamp": datetime.now().isoformat(),
        "alerts_generated": 0,
        "checks": {},
    }

    try:
        service = PostgresMonitorService()

        # 1. æ¥ç¶šæ•°ãƒã‚§ãƒƒã‚¯
        conn_stats = service.get_connection_stats()
        result["checks"]["connections"] = conn_stats

        if "error" not in conn_stats:
            usage_percent = conn_stats.get("usage_percent", 0)

            if usage_percent >= 95:
                send_multi_channel_notification.apply_async(
                    kwargs={
                        "channels": ["email", "teams", "dashboard"],
                        "title": "ğŸ”´ PostgreSQLæ¥ç¶šæ•°å±é™º",
                        "message": f"æ¥ç¶šä½¿ç”¨ç‡: {usage_percent}% "
                        f"({conn_stats['total']}/{conn_stats['max_connections']})\n"
                        f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {conn_stats['active']}, "
                        f"ã‚¢ã‚¤ãƒ‰ãƒ«: {conn_stats['idle']}",
                        "severity": "critical",
                    }
                )
                result["alerts_generated"] += 1

            elif usage_percent >= 80:
                send_multi_channel_notification.apply_async(
                    kwargs={
                        "channels": ["email", "dashboard"],
                        "title": "âš ï¸ PostgreSQLæ¥ç¶šæ•°è­¦å‘Š",
                        "message": f"æ¥ç¶šä½¿ç”¨ç‡: {usage_percent}% " f"({conn_stats['total']}/{conn_stats['max_connections']})",
                        "severity": "warning",
                    }
                )
                result["alerts_generated"] += 1

        # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãƒã‚§ãƒƒã‚¯
        cache_ratio = service.get_cache_hit_ratio()
        result["checks"]["cache_hit_ratio"] = cache_ratio

        if cache_ratio < 0.80:  # 80%æœªæº€
            send_multi_channel_notification.apply_async(
                kwargs={
                    "channels": ["email", "teams", "dashboard"],
                    "title": "ğŸ”´ PostgreSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡å±é™º",
                    "message": f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {cache_ratio:.2%}\n" f"shared_buffersã®å¢—åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                    "severity": "critical",
                }
            )
            result["alerts_generated"] += 1

        elif cache_ratio < 0.90:  # 90%æœªæº€
            send_multi_channel_notification.apply_async(
                kwargs={
                    "channels": ["dashboard"],
                    "title": "âš ï¸ PostgreSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ä½ä¸‹",
                    "message": f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {cache_ratio:.2%}",
                    "severity": "info",
                }
            )
            result["alerts_generated"] += 1

        # 3. VACUUMçµ±è¨ˆãƒã‚§ãƒƒã‚¯
        vacuum_stats = service.get_vacuum_stats()
        result["checks"]["vacuum"] = vacuum_stats

        if "error" not in vacuum_stats:
            needs_vacuum = vacuum_stats.get("needs_vacuum_count", 0)

            if needs_vacuum > 0:
                tables = vacuum_stats.get("tables_needing_vacuum", [])
                send_multi_channel_notification.apply_async(
                    kwargs={
                        "channels": ["dashboard"],
                        "title": f"ğŸ“Š VACUUMæ¨å¥¨ ({needs_vacuum}ãƒ†ãƒ¼ãƒ–ãƒ«)",
                        "message": f"ãƒ‡ãƒƒãƒ‰ã‚¿ãƒ—ãƒ«ãŒ10%ã‚’è¶…ãˆã¦ã„ã¾ã™: {', '.join(tables[:5])}",
                        "severity": "info",
                    }
                )
                result["alerts_generated"] += 1

        # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        db_size = service.get_database_size()
        result["checks"]["database_size"] = db_size

        # ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        result["status"] = "completed"
        logger.info(f"[Task {task_id}] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº† " f"(ã‚¢ãƒ©ãƒ¼ãƒˆ: {result['alerts_generated']}ä»¶)")

        return result

    except Exception as e:
        logger.exception(f"[Task {task_id}] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        result["status"] = "error"
        result["error"] = str(e)
        return result


@celery_app.task(
    bind=True,
    name="app.tasks.postgres_monitoring.generate_slow_query_report",
    max_retries=1,
)
def generate_slow_query_report(self) -> Dict[str, Any]:
    """
    ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

    æ—¥æ¬¡ã§ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªã‚’ãƒ¬ãƒãƒ¼ãƒˆã—ã€æœ€é©åŒ–ã®å‚è€ƒæƒ…å ±ã‚’æä¾›

    Returns:
        ãƒ¬ãƒãƒ¼ãƒˆçµæœ
    """
    from app.services.postgres_monitor_service import PostgresMonitorService
    from app.tasks.notification_tasks import send_multi_channel_notification

    task_id = self.request.id
    logger.info(f"[Task {task_id}] ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")

    result = {
        "task_id": task_id,
        "timestamp": datetime.now().isoformat(),
        "slow_query_count": 0,
    }

    try:
        service = PostgresMonitorService()

        # ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªå–å¾—ï¼ˆ1ç§’ä»¥ä¸Šï¼‰
        slow_queries = service.get_slow_queries(min_duration_ms=1000, limit=10)
        result["slow_query_count"] = len(slow_queries)

        if slow_queries:
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            report_lines = ["ğŸ“Š ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ¬ãƒãƒ¼ãƒˆ\n"]
            report_lines.append(f"æ¤œå‡ºæ•°: {len(slow_queries)}ä»¶\n\n")

            for i, query in enumerate(slow_queries[:5], 1):
                report_lines.append(
                    f"{i}. å¹³å‡å®Ÿè¡Œæ™‚é–“: {query['mean_time_ms']:.0f}ms "
                    f"(å‘¼ã³å‡ºã—: {query['calls']}å›)\n"
                    f"   ã‚¯ã‚¨ãƒª: {query['query']}\n"
                )

            send_multi_channel_notification.apply_async(
                kwargs={
                    "channels": ["dashboard"],
                    "title": f"ğŸ“Š ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ¬ãƒãƒ¼ãƒˆ ({len(slow_queries)}ä»¶)",
                    "message": "".join(report_lines),
                    "severity": "info",
                }
            )

            logger.info(f"[Task {task_id}] ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡å®Œäº†")

        result["status"] = "completed"
        return result

    except Exception as e:
        logger.exception(f"[Task {task_id}] ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        result["status"] = "error"
        result["error"] = str(e)
        return result


@celery_app.task(
    bind=True,
    name="app.tasks.postgres_monitoring.check_backup_status",
    max_retries=1,
)
def check_backup_status(self) -> Dict[str, Any]:
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯

    æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ç¢ºèªã—ã€å¤ã„å ´åˆã¯è­¦å‘Š

    Returns:
        ãƒã‚§ãƒƒã‚¯çµæœ
    """
    from pathlib import Path

    from app.tasks.notification_tasks import send_multi_channel_notification

    task_id = self.request.id
    logger.info(f"[Task {task_id}] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯é–‹å§‹")

    result = {
        "task_id": task_id,
        "timestamp": datetime.now().isoformat(),
    }

    try:
        backup_dir = Path(__file__).parent.parent.parent / "backups" / "postgres" / "daily"

        if not backup_dir.exists():
            logger.warning(f"[Task {task_id}] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            result["status"] = "no_backups"
            return result

        # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        dump_files = list(backup_dir.glob("backup_*.dump"))

        if not dump_files:
            send_multi_channel_notification.apply_async(
                kwargs={
                    "channels": ["email", "teams", "dashboard"],
                    "title": "ğŸ”´ PostgreSQLãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æœªå®Ÿè¡Œ",
                    "message": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    "severity": "critical",
                }
            )
            result["status"] = "no_backups"
            return result

        # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã‚’ç¢ºèª
        latest_file = max(dump_files, key=lambda p: p.stat().st_mtime)
        latest_time = datetime.fromtimestamp(latest_file.stat().st_mtime)
        age_hours = (datetime.now() - latest_time).total_seconds() / 3600

        result["latest_backup"] = {
            "file": latest_file.name,
            "time": latest_time.isoformat(),
            "age_hours": round(age_hours, 1),
            "size": latest_file.stat().st_size,
        }

        # 24æ™‚é–“ä»¥ä¸Šå¤ã„å ´åˆã¯è­¦å‘Š
        if age_hours > 24:
            send_multi_channel_notification.apply_async(
                kwargs={
                    "channels": ["email", "teams", "dashboard"],
                    "title": "âš ï¸ PostgreSQLãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå¤ã„",
                    "message": f"æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {latest_time.strftime('%Y-%m-%d %H:%M')}\n"
                    f"çµŒéæ™‚é–“: {age_hours:.1f}æ™‚é–“",
                    "severity": "warning",
                }
            )

        result["status"] = "completed"
        logger.info(f"[Task {task_id}] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯å®Œäº†")

        return result

    except Exception as e:
        logger.exception(f"[Task {task_id}] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        result["status"] = "error"
        result["error"] = str(e)
        return result
